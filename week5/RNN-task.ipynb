{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating names with recurrent neural networks\n",
    "\n",
    "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
    "\n",
    "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
    "\n",
    "It's dangerous to go alone, take these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.696201Z",
     "start_time": "2018-08-13T20:26:38.104103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import keras_utils\n",
    "import tqdm_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
    "\n",
    "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.701832Z",
     "start_time": "2018-08-13T20:26:42.697766Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_token = \" \"  # so that the network knows that we're generating a first token\n",
    "\n",
    "# this is the token for padding,\n",
    "# we will add fake pad token at the end of names \n",
    "# to make them of equal size for further batching\n",
    "pad_token = \"#\"\n",
    "\n",
    "with open(\"names\") as f:\n",
    "    names = f.read()[:-1].split('\\n')\n",
    "    names = [start_token + name for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.707885Z",
     "start_time": "2018-08-13T20:26:42.703302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples: 7944\n",
      " Abagael\n",
      " Claresta\n",
      " Glory\n",
      " Liliane\n",
      " Prissie\n",
      " Geeta\n",
      " Giovanne\n",
      " Piggy\n"
     ]
    }
   ],
   "source": [
    "print('number of samples:', len(names))\n",
    "for x in names[::1000]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.857411Z",
     "start_time": "2018-08-13T20:26:42.709371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 16\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEICAYAAAC55kg0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLgJmZhlzETAzy9j/B8WHKERRkkO/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fca78109908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = max(map(len, names))\n",
    "print(\"max length:\", MAX_LENGTH)\n",
    "\n",
    "plt.title('Sequence length distribution')\n",
    "plt.hist(list(map(len, names)), bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing\n",
    "\n",
    "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.864592Z",
     "start_time": "2018-08-13T20:26:42.858725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens: 56\n"
     ]
    }
   ],
   "source": [
    "tokens = set(''.join(names)) ### YOUR CODE HERE: all unique characters go here, padding included!\n",
    "tokens.add(pad_token)\n",
    "tokens = list(tokens)\n",
    "n_tokens = len(tokens)\n",
    "print ('n_tokens:', n_tokens)\n",
    "\n",
    "assert 50 < n_tokens < 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast everything from symbols into identifiers\n",
    "\n",
    "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
    "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
    "\n",
    "To create such dictionary, let's assign `token_to_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.870330Z",
     "start_time": "2018-08-13T20:26:42.866135Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_to_id = {key: val for val, key in enumerate(tokens)}### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
    "\n",
    "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.875943Z",
     "start_time": "2018-08-13T20:26:42.871834Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
    "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len, names))\n",
    "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        name_ix = list(map(token_to_id.get, names[i]))\n",
    "        names_ix[i, :len(name_ix)] = name_ix\n",
    "\n",
    "    return names_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.883107Z",
     "start_time": "2018-08-13T20:26:42.877186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Abagael\n",
      " Glory\n",
      " Prissie\n",
      " Giovanne\n",
      "[[45 46 37 19 41 19 54  3 13]\n",
      " [45 16  3 52 34  8 13 13 13]\n",
      " [45 47 34 27 28 28 27 54 13]\n",
      " [45 16 27 52 32 19 10 10 54]]\n"
     ]
    }
   ],
   "source": [
    "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
    "print('\\n'.join(names[::2000]))\n",
    "print(to_matrix(names[::2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a recurrent neural network\n",
    "\n",
    "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
    "<img src=\"./rnn.png\" width=600>\n",
    "\n",
    "Since we're training a language model, there should also be:\n",
    "* An embedding layer that converts character id x_t to a vector.\n",
    "* An output layer that predicts probabilities of next phoneme based on h_t+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.039419Z",
     "start_time": "2018-08-13T20:26:42.884581Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remember to reset your session if you change your graph!\n",
    "s = keras_utils.reset_tf_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.044903Z",
     "start_time": "2018-08-13T20:26:44.041084Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import concatenate, Dense, Embedding\n",
    "\n",
    "rnn_num_units = 64  # size of hidden state\n",
    "embedding_size = 16  # for characters\n",
    "\n",
    "# Let's create layers for our recurrent network\n",
    "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
    "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
    "\n",
    "# an embedding layer that converts character ids into embeddings\n",
    "embed_x = Embedding(n_tokens, embedding_size)\n",
    "\n",
    "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
    "get_h_next = Dense(rnn_num_units, activation = 'relu') ### YOUR CODE HERE\n",
    "\n",
    "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
    "get_probas = Dense(n_tokens, activation='softmax') ### YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate names character by character starting with `start_token`:\n",
    "\n",
    "<img src=\"./char-nn.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.053212Z",
     "start_time": "2018-08-13T20:26:44.048389Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_one_step(x_t, h_t):\n",
    "    \"\"\"\n",
    "    Recurrent neural network step that produces \n",
    "    probabilities for next token x_t+1 and next state h_t+1\n",
    "    given current input x_t and previous state h_t.\n",
    "    We'll call this method repeatedly to produce the whole sequence.\n",
    "    \n",
    "    You're supposed to \"apply\" above layers to produce new tensors.\n",
    "    Follow inline instructions to complete the function.\n",
    "    \"\"\"\n",
    "    # convert character id into embedding\n",
    "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
    "    \n",
    "    # concatenate x_t embedding and previous h_t state\n",
    "    x_and_h = concatenate([x_t_emb, h_t])\n",
    "    print(\"h_t\",tf.shape(h_t))\n",
    "    print(\"x_t\",tf.shape(x_t))\n",
    "    print(\"x_t\", tf.shape(x_t_emb))\n",
    "    # compute next state given x_and_h\n",
    "    h_next = get_h_next(x_and_h)### YOUR CODE HERE\n",
    "    \n",
    "    # get probabilities for language model P(x_next|h_next)\n",
    "    output_probas = get_probas(h_next)### YOUR CODE HERE\n",
    "    \n",
    "    return output_probas, h_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loop\n",
    "\n",
    "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
    "\n",
    "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.342948Z",
     "start_time": "2018-08-13T20:26:44.056136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_t Tensor(\"Shape_69:0\", shape=(2,), dtype=int32)\n",
      "x_t Tensor(\"Shape_70:0\", shape=(1,), dtype=int32)\n",
      "x_t Tensor(\"Shape_71:0\", shape=(2,), dtype=int32)\n",
      "h_t Tensor(\"Shape_72:0\", shape=(2,), dtype=int32)\n",
      "x_t Tensor(\"Shape_73:0\", shape=(1,), dtype=int32)\n",
      "x_t Tensor(\"Shape_74:0\", shape=(2,), dtype=int32)\n",
      "h_t Tensor(\"Shape_75:0\", shape=(2,), dtype=int32)\n",
      "x_t Tensor(\"Shape_76:0\", shape=(1,), dtype=int32)\n",
      "x_t Tensor(\"Shape_77:0\", shape=(2,), dtype=int32)\n",
      "h_t Tensor(\"Shape_78:0\", shape=(2,), dtype=int32)\n",
      "x_t Tensor(\"Shape_79:0\", shape=(1,), dtype=int32)\n",
      "x_t Tensor(\"Shape_80:0\", shape=(2,), dtype=int32)\n",
      "h_t Tensor(\"Shape_81:0\", shape=(2,), dtype=int32)\n",
      "x_t Tensor(\"Shape_82:0\", shape=(1,), dtype=int32)\n",
      "x_t Tensor(\"Shape_83:0\", shape=(2,), dtype=int32)\n",
      "h_t Tensor(\"Shape_84:0\", shape=(2,), dtype=int32)\n",
      "x_t Tensor(\"Shape_85:0\", shape=(1,), dtype=int32)\n",
      "x_t Tensor(\"Shape_86:0\", shape=(2,), dtype=int32)\n",
      "h_t Tensor(\"Shape_87:0\", shape=(2,), dtype=int32)\n",
      "x_t Tensor(\"Shape_88:0\", shape=(1,), dtype=int32)\n",
      "x_t Tensor(\"Shape_89:0\", shape=(2,), dtype=int32)\n",
      "h_t Tensor(\"Shape_90:0\", shape=(2,), dtype=int32)\n",
      "x_t Tensor(\"Shape_91:0\", shape=(1,), dtype=int32)\n",
      "x_t Tensor(\"Shape_92:0\", shape=(2,), dtype=int32)\n",
      "h_t Tensor(\"Shape_93:0\", shape=(2,), dtype=int32)\n",
      "x_t Tensor(\"Shape_94:0\", shape=(1,), dtype=int32)\n",
      "x_t Tensor(\"Shape_95:0\", shape=(2,), dtype=int32)\n",
      "h_t Tensor(\"Shape_96:0\", shape=(2,), dtype=int32)\n",
      "x_t Tensor(\"Shape_97:0\", shape=(1,), dtype=int32)\n",
      "x_t Tensor(\"Shape_98:0\", shape=(2,), dtype=int32)\n",
      "h_t Tensor(\"Shape_99:0\", shape=(2,), dtype=int32)\n",
      "x_t Tensor(\"Shape_100:0\", shape=(1,), dtype=int32)\n",
      "x_t Tensor(\"Shape_101:0\", shape=(2,), dtype=int32)\n",
      "h_t Tensor(\"Shape_102:0\", shape=(2,), dtype=int32)\n",
      "x_t Tensor(\"Shape_103:0\", shape=(1,), dtype=int32)\n",
      "x_t Tensor(\"Shape_104:0\", shape=(2,), dtype=int32)\n",
      "h_t Tensor(\"Shape_105:0\", shape=(2,), dtype=int32)\n",
      "x_t Tensor(\"Shape_106:0\", shape=(1,), dtype=int32)\n",
      "x_t Tensor(\"Shape_107:0\", shape=(2,), dtype=int32)\n",
      "h_t Tensor(\"Shape_108:0\", shape=(2,), dtype=int32)\n",
      "x_t Tensor(\"Shape_109:0\", shape=(1,), dtype=int32)\n",
      "x_t Tensor(\"Shape_110:0\", shape=(2,), dtype=int32)\n",
      "h_t Tensor(\"Shape_111:0\", shape=(2,), dtype=int32)\n",
      "x_t Tensor(\"Shape_112:0\", shape=(1,), dtype=int32)\n",
      "x_t Tensor(\"Shape_113:0\", shape=(2,), dtype=int32)\n",
      "h_t Tensor(\"Shape_114:0\", shape=(2,), dtype=int32)\n",
      "x_t Tensor(\"Shape_115:0\", shape=(1,), dtype=int32)\n",
      "x_t Tensor(\"Shape_116:0\", shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
    "batch_size = tf.shape(input_sequence)[0]\n",
    "\n",
    "predicted_probas = []\n",
    "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
    "\n",
    "for t in range(MAX_LENGTH):\n",
    "    x_t = input_sequence[:, t]  # column t\n",
    "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
    "    \n",
    "    h_prev = h_next\n",
    "    predicted_probas.append(probas_next)\n",
    "    \n",
    "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
    "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
    "\n",
    "# next to last token prediction is not needed\n",
    "predicted_probas = predicted_probas[:, :-1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loss and gradients\n",
    "\n",
    "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
    "\n",
    "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
    "\n",
    "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.354310Z",
     "start_time": "2018-08-13T20:26:44.344648Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flatten predictions to [batch*time, n_tokens]\n",
    "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
    "\n",
    "# flatten answers (next tokens) and one-hot encode them\n",
    "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
    "\n",
    "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
    "\n",
    "For simplicity you can ignore this comment, it's up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:45.076642Z",
     "start_time": "2018-08-13T20:26:44.355594Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
    "# Mind that predictions are probabilities and NOT logits!\n",
    "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
    "loss = tf.reduce_mean(keras.losses.categorical_crossentropy(answers_matrix, predictions_matrix))### YOUR CODE HERE\n",
    "\n",
    "optimize = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.322187Z",
     "start_time": "2018-08-13T20:26:45.078296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHEiDu1JKOdD/Bz2fKuMSy8R3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fca1474feb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_size = 32\n",
    "history = []\n",
    "\n",
    "for i in range(1000):\n",
    "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
    "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
    "    \n",
    "    history.append(loss_i)\n",
    "    \n",
    "    if (i + 1) % 100 == 0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history, label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: sampling\n",
    "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.341196Z",
     "start_time": "2018-08-13T20:26:55.323787Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_t = tf.placeholder(tf.int32, (1,))\n",
    "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
    "\n",
    "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
    "# We reuse all parameters thanks to functional API usage.\n",
    "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
    "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
    "next_probs, next_h = rnn_one_step(x_t, h_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.346422Z",
     "start_time": "2018-08-13T20:26:55.342659Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
    "    '''\n",
    "    This function generates text given a `seed_phrase` as a seed.\n",
    "    Remember to include start_token in seed phrase!\n",
    "    Parameter `max_length` is used to set the number of characters in prediction.\n",
    "    '''\n",
    "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
    "    s.run(tf.assign(h_t, h_t.initial_value))\n",
    "    \n",
    "    # feed the seed phrase, if any\n",
    "    for ix in x_sequence[:-1]:\n",
    "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
    "    \n",
    "    # start generating\n",
    "    for _ in range(max_length-len(seed_phrase)):\n",
    "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
    "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:58.458115Z",
     "start_time": "2018-08-13T20:26:55.347900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Gelsbte\n",
      " Elnina\n",
      " Flinitin\n",
      " Corna\n",
      " Nelg\n",
      " feyre\n",
      " Geedie\n",
      " Rarme\n",
      " Goaghine\n",
      " Geysy\n"
     ]
    }
   ],
   "source": [
    "# without prefix\n",
    "for _ in range(10):\n",
    "    print(generate_sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:01.986726Z",
     "start_time": "2018-08-13T20:26:58.459810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trumpa\n",
      " Trumpanns\n",
      " Trumpik\n",
      " Trumphan\n",
      " Trumpa\n",
      " Trumpyr\n",
      " Trumpo\n",
      " Trumpyr\n",
      " Trumpeana\n",
      " Trumpso\n"
     ]
    }
   ],
   "source": [
    "# with prefix conditioning\n",
    "for _ in range(10):\n",
    "    print(generate_sample(' Trump'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to Coursera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:02.004926Z",
     "start_time": "2018-08-13T20:40:02.000821Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# token expires every 30 min\n",
    "COURSERA_TOKEN = \"G0AMhQqGZxhlGLiD\"\n",
    "COURSERA_EMAIL = \"muz149@psu.edu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:18.923357Z",
     "start_time": "2018-08-13T20:40:03.549343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af31efbf82ef4517816fab7c8465035e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submitted to Coursera platform. See results on assignment page!\n"
     ]
    }
   ],
   "source": [
    "from submit import submit_char_rnn\n",
    "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
    "submission = (history, samples)\n",
    "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try it out!\n",
    "\n",
    "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
    "\n",
    "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
    "\n",
    "* Novels/poems/songs of your favorite author\n",
    "* News titles/clickbait titles\n",
    "* Source code of Linux or Tensorflow\n",
    "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
    "* Melody in notes/chords format\n",
    "* IKEA catalog titles\n",
    "* Pokemon names\n",
    "* Cards from Magic, the Gathering / Hearthstone\n",
    "\n",
    "If you're willing to give it a try, here's what you wanna look at:\n",
    "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
    "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
    "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
    "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
    "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
    "\n",
    "__Good hunting!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Bonus level: dynamic RNNs\n",
    "\n",
    "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
    "\n",
    "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
    "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
    "\n",
    "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.975354Z",
     "start_time": "2018-08-13T20:27:12.737529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM outputs for each step [batch,time,n_tokens]:\n",
      "(10, 50, 56)\n"
     ]
    }
   ],
   "source": [
    "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
    "    def call(self, input, state):\n",
    "        # from docs:\n",
    "        # Returns:\n",
    "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
    "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
    "        return rnn_one_step(input[:, 0], state)\n",
    "    \n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return n_tokens\n",
    "    \n",
    "cell = CustomRNN(rnn_num_units)\n",
    "\n",
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "    \n",
    "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
    "\n",
    "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
    "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
    "\n",
    "You can also use any pre-implemented RNN cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.981697Z",
     "start_time": "2018-08-13T20:27:12.977590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tTimeFreqLSTMCell\tUGRNNCell\t"
     ]
    }
   ],
   "source": [
    "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
    "    if obj.endswith('Cell'):\n",
    "        print(obj, end=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:13.168207Z",
     "start_time": "2018-08-13T20:27:12.986884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM hidden state for each step [batch,time,rnn_num_units]:\n",
      "(10, 50, 64)\n"
     ]
    }
   ],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "\n",
    "inputs_embedded = embed_x(input_sequence)\n",
    "\n",
    "# standard cell returns hidden state as output!\n",
    "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
    "\n",
    "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
    "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
